#!/usr/bin/env python3
"""
BERTæœ¬åœ°æ¨¡å‹åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
"""

import torch
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.model_loader import BERTLocalLoader, bert_loader
from utils.text_processor import TextProcessor

def demo_basic_loading():
    """æ¼”ç¤ºåŸºç¡€åŠ è½½"""
    print("ğŸ”§ 1. æ¨¡å‹åŠ è½½æ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–åŠ è½½å™¨
    loader = BERTLocalLoader()
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    info = loader.get_model_info()
    print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   - å‚æ•°é‡: {info['parameters']:,}")
    print(f"   - éšè—å±‚: {info['layers']}")
    print(f"   - éšè—ç»´åº¦: {info['hidden_size']}")
    print(f"   - æ³¨æ„åŠ›å¤´: {info['attention_heads']}")
    print(f"   - è¿è¡Œè®¾å¤‡: {info['device']}")

def demo_text_processing():
    """æ¼”ç¤ºæ–‡æœ¬å¤„ç†"""
    print("\nğŸ“ 2. æ–‡æœ¬å¤„ç†æ¼”ç¤º")
    print("=" * 50)
    
    processor = TextProcessor()
    
    # ç¤ºä¾‹æ–‡æœ¬
    texts = [
        "Hello, BERT! This is amazing.",
        "I love natural language processing.",
        "Transformers are powerful deep learning models.",
        "The weather is beautiful today."
    ]
    
    for i, text in enumerate(texts, 1):
        print(f"\n{i}. å¤„ç†æ–‡æœ¬: '{text}'")
        
        # åˆ†è¯
        inputs = processor.tokenize_text(text)
        print(f"   Token IDs: {inputs['input_ids'].shape}")
        print(f"   æ³¨æ„åŠ›æ©ç : {inputs['attention_mask'].shape}")
        
        # è·å–åµŒå…¥
        embeddings = processor.get_embeddings(text)
        print(f"   éšè—çŠ¶æ€: {embeddings['last_hidden_state'].shape}")
        print(f"   å¥å­åµŒå…¥: {embeddings['pooler_output'].shape}")

def demo_advanced_features():
    """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
    print("\nğŸ¯ 3. é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    processor = TextProcessor()
    
    # æ‰¹é‡å¤„ç†
    texts = ["Text " + str(i) for i in range(10)]
    batch_embeddings = processor.batch_process(texts, batch_size=4)
    print(f"ğŸ“¦ æ‰¹é‡å¤„ç† {len(texts)} ä¸ªæ–‡æœ¬")
    print(f"   æ‰¹é‡åµŒå…¥å½¢çŠ¶: {batch_embeddings.shape}")
    
    # å•ä¸ªå¥å­åµŒå…¥
    sample_text = "This is a sample sentence for embedding."
    sentence_embedding = processor.get_sentence_embedding(sample_text)
    print(f"\nğŸ” å¥å­åµŒå…¥ç¤ºä¾‹:")
    print(f"   æ–‡æœ¬: '{sample_text}'")
    print(f"   åµŒå…¥ç»´åº¦: {sentence_embedding.shape}")
    print(f"   å‰5ä¸ªå€¼: {sentence_embedding[:5].cpu().numpy()}")

if __name__ == "__main__":
    print("ğŸ¤– BERTæœ¬åœ°æ¨¡å‹å®Œå…¨ä½¿ç”¨æŒ‡å—")
    print("ğŸ“ æ¨¡å‹è·¯å¾„: ./models/bert-base-uncased/")
    print("-" * 60)
    
    try:
        # è¿è¡Œæ¼”ç¤º
        demo_basic_loading()
        demo_text_processing()
        demo_advanced_features()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼æ‚¨ç°åœ¨å¯ä»¥ï¼š")
        print("   1. ä¿®æ”¹æ–‡æœ¬è¿›è¡Œå®éªŒ")
        print("   2. å°è¯•ä¸åŒçš„æ‰¹é‡å¤§å°")
        print("   3. æ¢ç´¢å…¶ä»–BERTåŠŸèƒ½")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´ä¸‹è½½")