import torch
import torch.nn as nn
from utils.text_processor import TextProcessor

class SimpleTextClassifier(nn.Module):
    """åŸºäºBERTçš„ç®€å•æ–‡æœ¬åˆ†ç±»å™¨"""
    
    def __init__(self, num_classes: int = 2):
        super().__init__()
        self.text_processor = TextProcessor()
        self.classifier = nn.Linear(768, num_classes)  # BERTéšè—ç»´åº¦æ˜¯768
        
    def forward(self, texts):
        # è·å–BERTåµŒå…¥
        with torch.no_grad():  # å†»ç»“BERTæƒé‡
            embeddings = self.text_processor.get_embeddings(texts)
            cls_embeddings = embeddings['pooler_output']
        
        # åˆ†ç±»
        return self.classifier(cls_embeddings)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ§  åŸºäºBERTçš„æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹")
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    classifier = SimpleTextClassifier(num_classes=3)
    
    # ç¤ºä¾‹æ–‡æœ¬å’Œæ ‡ç­¾ï¼ˆæƒ…æ„Ÿåˆ†æï¼‰
    texts = [
        "I love this product!",
        "This is terrible.",
        "It's okay, not great.",
        "Amazing experience!",
        "Very disappointed."
    ]
    
    # å‡æƒ³çš„é¢„æµ‹
    with torch.no_grad():
        predictions = classifier(texts)
        probs = torch.softmax(predictions, dim=1)
        
        print("\nğŸ“Š åˆ†ç±»é¢„æµ‹:")
        for i, (text, prob) in enumerate(zip(texts, probs)):
            print(f"{i+1}. '{text}'")
            print(f"   æ¦‚ç‡: {prob.cpu().numpy().round(3)}")